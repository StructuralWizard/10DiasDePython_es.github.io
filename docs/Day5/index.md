---
title: D√≠a 5 Web Scraping con Beautiful Soup y Selenium
layout: default
nav_order: 6
has_children: false
nav_exclude: false
---

# D√≠a 5. Web Scraping. üï∑Ô∏è Beautiful Soup y Selenium
{: .no_toc }

¬°Bienvenido al D√≠a 5! Hoy aprender√°s a extraer datos de sitios web usando Python. Empezaremos con Beautiful Soup para p√°ginas est√°ticas, y luego pasaremos a Selenium para sitios din√°micos e interactivos. ¬°Al final, podr√°s recolectar datos de la web para tus propios proyectos!

---

<details open markdown="block">
  <summary>
    √çndice de contenidos
  </summary>
  {: .text-delta }
1. TOC
{:toc}
</details>

---

## üå± ¬øQu√© es el Web Scraping?
El web scraping es el proceso de recopilar informaci√≥n de sitios web de forma autom√°tica. Es √∫til para recopilar datos que no est√°n disponibles a trav√©s de una API.

- **Beautiful Soup**: Analiza documentos HTML y XML. Ideal para p√°ginas est√°ticas.
- **Selenium**: Automatiza navegadores. √ötil para sitios din√°micos que requieren interacci√≥n (clics, escritura, etc.).

---

## ü•£ Conceptos b√°sicos de Beautiful Soup <a href="#top" class="back-to-top-link" aria-label="Back to Top">‚Üë</a>
Para analizar y navegar por HTML/XML con Python
Requiere: beautifulsoup4 y un analizador como lxml o el analizador html.parser integrado de Python.

### üß© ¬øQu√© puedes hacer con Beautiful soup?
Aqu√≠ hay un desglose de sus capacidades principales:

* **Analizar HTML y XML:** Beautiful Soup toma contenido HTML o XML sin procesar y lo transforma en un "√°rbol de an√°lisis" navegable hecho de objetos de Python. Este √°rbol simplifica el acceso y la manipulaci√≥n de partes espec√≠ficas del documento.

* **Navegar por el √°rbol de an√°lisis:** Puedes moverte f√°cilmente a trav√©s de la estructura HTML/XML:
    * **Por nombre de etiqueta:** Encuentra elementos como `<div>`, `<a>` o `<p>`.
    * **Por atributos:** Localiza elementos seg√∫n su `id`, `class`, `href` o cualquier otro atributo.
    * **Por contenido de texto:** Busca palabras o frases espec√≠ficas dentro de los elementos.
    * **Usando relaciones:** Viaja hacia arriba (padre), hacia abajo (hijos, descendientes) o hacia los lados (hermanos) en el √°rbol.

* **Buscar elementos espec√≠ficos:** Beautiful Soup ofrece m√©todos potentes como `find()` (para obtener la primera coincidencia) y `find_all()` (para obtener todas las coincidencias) para localizar los datos exactos que est√°s buscando. Puedes combinar estos con varios filtros (nombres de etiquetas, atributos, selectores CSS, expresiones regulares o incluso funciones personalizadas) para una selecci√≥n precisa.

* **Extraer datos:** Una vez que has encontrado los elementos que quieres, puedes extraer f√°cilmente:
    * **Contenido de texto:** Obt√©n el texto visible dentro de una etiqueta (p. ej., `soup.title.string`).
    * **Valores de atributos:** Accede a los valores de atributos como `href` de una etiqueta `<a>` o `src` de una etiqueta `<img>`.

* **Manejar HTML mal formado:** Una de las fortalezas de Beautiful Soup es su capacidad para lidiar con "sopa de etiquetas"‚ÄîHTML mal estructurado o incompleto. Intenta darle sentido y construir un √°rbol de an√°lisis utilizable.

* **Integrarse con otras bibliotecas:**
    * **Requests:** A menudo se usa con la biblioteca `requests` para obtener el contenido HTML de una URL antes de que Beautiful Soup lo analice.
    * **Selenium:** Para sitios web din√°micos que dependen en gran medida de JavaScript para el renderizado, puedes usar Selenium (una herramienta de automatizaci√≥n de navegador) para cargar la p√°gina y luego pasar el HTML renderizado a Beautiful Soup para su an√°lisis.
    * **Pandas:** Los datos extra√≠dos se pueden estructurar y almacenar f√°cilmente en DataFrames de Pandas para un an√°lisis posterior o para exportarlos a formatos como CSV o Excel.

---

### üß∞ Usos Comunes de Beautiful Soup

Beautiful Soup se utiliza principalmente para:

* **Web Scraping:** Este es su prop√≥sito principal. Puedes usarlo para:
    * Recopilar informaci√≥n de productos (nombres, precios, descripciones) de sitios de comercio electr√≥nico.
    * Extraer art√≠culos de noticias, publicaciones de blogs o trabajos de investigaci√≥n.
    * Recopilar listados de trabajo o datos inmobiliarios.
    * Realizar an√°lisis de sentimientos raspando rese√±as o comentarios.
* **Miner√≠a de Datos:** Convertir datos web no estructurados en conjuntos de datos organizados para su an√°lisis.
* **Agregaci√≥n de Contenido:** Crear herramientas que extraen contenido de m√∫ltiples fuentes en l√≠nea a una ubicaci√≥n centralizada.

En resumen, Beautiful Soup permite a los desarrolladores de Python interactuar program√°ticamente con el contenido web, lo que lo convierte en una herramienta esencial para cualquiera que busque extraer y trabajar con datos de Internet.

### üì¶ Instalar los paquetes necesarios
```bash
pip install beautifulsoup4 requests lxml
```

### üìÑ Ejemplo: Raspado de un archivo HTML local
Supongamos que tienes un archivo llamado `website.html`:

```python
from bs4 import BeautifulSoup

with open("website.html", encoding="utf-8") as file:
    contents = file.read()

soup = BeautifulSoup(contents, "html.parser")
print(soup.title)
```

### üßº Limpieza de HTML
```python
clean_text = soup.get_text(strip=True)
```

### üîç Encontrar Elementos
Puedes buscar por etiquetas, clases, ids y m√°s:

```python
# Encontrar la primera etiqueta <a>
anchor = soup.find("a")
print(anchor)

# Encontrar todas las etiquetas <a>
all_anchors = soup.find_all("a")
for tag in all_anchors:
    # .getText() obtiene el texto visible dentro de la etiqueta
    print(tag.getText())
    # .get() recupera el valor de un atributo (p. ej., href)
    print(tag.get("href"))
```

#### Buscar por atributos (id, clase, etc.)
```python
# Encontrar por id
heading = soup.find(name="h1", id="name")

# Encontrar por clase (nota: usa class_ porque 'class' es una palabra reservada)
section = soup.find(name="h3", class_="heading")

# Encontrar todos los elementos con una clase espec√≠fica
items = soup.find_all(class_="item")
```

#### Buscar usando selectores CSS
```python
# Usa .select() para selectores CSS
links = soup.select("a.storylink")  # Todas las etiquetas <a> con la clase 'storylink'
ids = soup.select("#main")          # Elemento con id 'main'
classes = soup.select(".heading")   # Todos los elementos con la clase 'heading'
```

### üå≥ Navegando por el √Årbol
```python
tag.name         # Nombre de la etiqueta
tag.attrs        # Atributos de la etiqueta como dict
tag['href']      # Atributo espec√≠fico

tag.text         # Todo el texto dentro de la etiqueta (recursivo)
tag.string       # Solo la cadena directa
tag.parent
tag.children      # Generador de hijos
tag.contents      # Lista de hijos
tag.next_sibling
tag.previous_sibling

```


### üîó Navegando y Siguiendo Enlaces
Puedes extraer y seguir enlaces combinando `.get("href")` con requests:

```python
for tag in soup.find_all("a"):
    link = tag.get("href")
    if link and link.startswith("http"):
        print("Siguiendo:", link)
        # Puedes obtener la p√°gina enlazada con requests.get(link)
```

Para m√°s referencias, sigue la <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank">documentaci√≥n</a>


---

## üåê Raspado de Sitios Web en Vivo <a href="#top" class="back-to-top-link" aria-label="Back to Top">‚Üë</a>

Para raspar un sitio web en vivo, usa la biblioteca `requests` para obtener la p√°gina:

```python
import requests
from bs4 import BeautifulSoup

url = "https://news.ycombinator.com/"
response = requests.get(url)
webpage = response.text
soup = BeautifulSoup(webpage, "html.parser")

# Obtener todos los t√≠tulos de los art√≠culos
titles = soup.find_all("a", class_="storylink")
for title in titles:
    print(title.getText())
```

---

## ‚öñÔ∏è ¬øEs Legal el Web Scraping? <a href="#top" class="back-to-top-link" aria-label="Back to Top">‚Üë</a>

- Solo raspa datos p√∫blicos.
- Respeta el archivo robots.txt y los t√©rminos del sitio web.
- No sobrecargues los servidores (agrega retrasos si raspas muchas p√°ginas).
- Usa los datos raspados de manera responsable.

---

## ü§ñ Selenium para Sitios Web Din√°micos <a href="#top" class="back-to-top-link" aria-label="Back to Top">‚Üë</a>

Algunos sitios cargan contenido con JavaScript o requieren interacci√≥n. Selenium te permite controlar un navegador real para manejar estos casos.

A diferencia de Beautiful Soup, que se limita a raspar datos, Selenium permite la interacci√≥n con las p√°ginas web, como escribir, hacer clic y desplazarse. Permite la automatizaci√≥n de acciones continuas y flujos de trabajo completos de un trabajo o tarea en particular. Conduce eficazmente un navegador para realizar acciones como un usuario humano.

Selenium puede automatizar casi cualquier cosa que un humano pueda hacer en un sitio web, como rellenar formularios, transferir informaci√≥n o jugar juegos basados en la web.

### üöó Introducci√≥n a Selenium WebDriver

* **Qu√© es:** Selenium WebDriver es una conocida herramienta de automatizaci√≥n y prueba para desarrolladores web.
* **Por qu√© usarlo (en lugar de Beautiful Soup):** A diferencia de Beautiful Soup, que se limita a raspar datos, Selenium permite la interacci√≥n con las p√°ginas web, como escribir, hacer clic y desplazarse. Permite la automatizaci√≥n de acciones continuas y flujos de trabajo completos de un trabajo o tarea en particular. Conduce eficazmente un navegador para realizar acciones como un usuario humano.
* **Capacidades:** Selenium puede automatizar casi cualquier cosa que un humano pueda hacer en un sitio web, como rellenar formularios, transferir informaci√≥n o jugar juegos basados en la web.

### üîß Instalaci√≥n y Configuraci√≥n de Selenium

1.  **Instalar el navegador Chrome:** Aunque Selenium funciona con otros navegadores como Firefox o Safari, se recomienda Chrome por su consistencia y el uso de las Herramientas de Desarrollo de Chrome. Descarga el controlador de Chrome desde [chromedriver.chromium.org](https://chromedriver.chromium.org/downloads) y col√≥calo en tu RUTA.
2.  **Instalar el paquete de Selenium:**
    * Importa `selenium` en tu archivo de Python (p. ej., `main.py`).
    * Instala el paquete usando la opci√≥n de bombilla proporcionada en tu IDE.
```bash
pip install selenium
```
3.  **Importar el M√≥dulo WebDriver:** Cambia la declaraci√≥n de importaci√≥n a `from selenium import webdriver`.
4.  **Crear una Instancia de Driver:** Inicializa un objeto de controlador de Chrome: `driver = webdriver.Chrome()`.
    * **Chromedriver:** Act√∫a como un puente entre el c√≥digo de Selenium y el navegador Chrome, dici√©ndole a Selenium c√≥mo interactuar con el navegador. Existen diferentes controladores para diferentes navegadores (p. ej., Safari, Firefox).
5.  **Control del Navegador:**
    * `driver.close()`: Cierra la pesta√±a activa.
    * `driver.quit()`: Cierra todo el navegador. Se prefiere usar `quit()` despu√©s de completar las tareas para asegurar una instancia de navegador nueva para futuras ejecuciones.

### üîé Ejemplo: Abrir una P√°gina y Encontrar un Elemento
```python
from selenium import webdriver
from selenium.webdriver.common.by import By
import time as time_module

# Iniciar el navegador
browser = webdriver.Chrome()
browser.get("https://www.python.org")

# Encontrar elementos
event_times = browser.find_elements(By.CSS_SELECTOR, ".event-widget time")
event_names = browser.find_elements(By.CSS_SELECTOR, ".event-widget li a")

for time, name in zip(event_times, event_names):
    print(time.text, name.text)

# Esperar 3 segundos antes de cerrar
time_module.sleep(3)

browser.quit()
```

### üîç Encontrar y Seleccionar Elementos en un Sitio Web

**Localizaci√≥n de Elementos:**

Selenium ofrece varias estrategias para encontrar elementos HTML en una p√°gina web. Una vez que has identificado un elemento con la herramienta de inspecci√≥n del navegador, puedes copiar su Xpath u otro y usarlo como identificador con:

* **M√©todo `find_element()`:** Se usa para encontrar un solo elemento.
* **Clase `By`:** Importante para especificar la estrategia de localizaci√≥n (p. ej., `By.CLASS_NAME`, `By.ID`, `By.NAME`, `By.LINK_TEXT`).
* **Ejemplos:**
    * **Por Nombre de Clase:** Para obtener el precio de un art√≠culo en Amazon, podr√≠as encontrar elementos con clases como "a-price-whole" (para los d√≥lares) y "a-price-fraction" (para los centavos).
    * **Acceder al Contenido de Texto:** Despu√©s de encontrar un elemento, usa `.text` para recuperar el contenido de texto dentro de ese elemento HTML.
    * **Por Nombre:** √ötil para campos de entrada de formularios.
    * **Por Texto del Enlace:** Espec√≠ficamente para hacer clic en enlaces por su texto visible.
* **M√©todo `find_elements()`:** Por cada m√©todo `find_element()`, hay un hom√≥logo `find_elements()` que devuelve una lista de todos los elementos coincidentes.
* **Inspeccionar Elementos:** Usa las Herramientas de Desarrollo de Chrome (clic derecho -> Inspeccionar) para examinar la estructura HTML e identificar IDs, nombres de clase u otros atributos de los elementos.

### üñ±Ô∏è Automatizaci√≥n de Interacciones (Escribir y Hacer Clic)

* **Hacer Clic en Elementos:**
    * Despu√©s de identificar un elemento, usa el m√©todo `.click()` en el objeto del elemento.
    * Selenium puede hacer clic en enlaces bas√°ndose en su `LINK_TEXT`.
* **Escribir en Campos de Entrada:**
    * Primero, encuentra el elemento del campo de entrada.
    * Usa el m√©todo `.send_keys()` en el objeto del elemento, pasando la cadena que quieres escribir.
* **Enviar Teclas Especiales:** Para enviar teclas como `Enter` o `Return`, importa la clase `Keys` desde `selenium.webdriver.common.keys`.


---

## üìù Desaf√≠o: Raspar los Pr√≥ximos Eventos de Python <a href="#top" class="back-to-top-link" aria-label="Back to Top">‚Üë</a>

- Usa Selenium para abrir [python.org](https://www.python.org/)
- Extrae la fecha y el nombre de los pr√≥ximos 5 eventos
- Gu√°rdalos en un diccionario como:

```python
events = {
    0: {"time": "2025-06-11", "name": "PyCon"},
    1: {"time": "2025-06-18", "name": "DjangoCon"},
    # ...
}
```

---

## üöÄ Resumen <a href="#top" class="back-to-top-link" aria-label="Back to Top">‚Üë</a>

- Usa Beautiful Soup para el raspado de HTML est√°tico
- Usa Selenium para sitios din√°micos e interactivos
- Respeta siempre las reglas y la √©tica del sitio web

Ahora tienes las herramientas para recopilar datos de casi cualquier sitio web. ¬°Feliz raspado!
